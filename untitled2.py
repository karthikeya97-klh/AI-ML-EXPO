# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12Bf01VyLoAsicnXArY_o7Y9k6xOVH3-6
"""

#OS libs
import os
import shutil
import itertools
import pathlib


#Data handling tools
import cv2
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
sns.set_style('whitegrid')
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix , classification_report

#Deep learning libs
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D , MaxPooling2D , Flatten , Activation , Dense , Dropout , BatchNormalization
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam , Adamax
from tensorflow.keras import regularizers

import os
import zipfile
import pandas as pd

# Path to the zip file
train_data_dir = '/content/archive.zip'

# Define the extraction path
extraction_dir = '/content/archive_extracted'

# Extract the zip file if it's not already extracted
if not os.path.exists(extraction_dir):
    with zipfile.ZipFile(train_data_dir, 'r') as zip_ref:
        zip_ref.extractall(extraction_dir)

# Now, you can list the contents of the extracted directory
filepaths = []
labels = []

# Assuming the structure is similar to folders for each class inside the zip
folds = os.listdir(extraction_dir)

for fold in folds:
    foldpath = os.path.join(extraction_dir, fold)

    # Check if the fold is indeed a directory (important for subfolders in zip)
    if os.path.isdir(foldpath):
        filelist = os.listdir(foldpath)

        for file in filelist:
            fpath = os.path.join(foldpath, file)

            # Append the file path and its label (the folder name)
            filepaths.append(fpath)
            labels.append(fold)

# Create a dataframe combining file paths and labels
Fseries = pd.Series(filepaths, name='filepaths')
Lseries = pd.Series(labels, name='labels')
train_df = pd.concat([Fseries, Lseries], axis=1)

# Show the first few rows of the dataframe
print(train_df.head())

train_df.head()

import os
import zipfile
import pandas as pd

# Path to the zip file
test_data_dir = '/content/archive.zip'

# Define the extraction path for test data
extraction_dir = '/content/test_data_extracted'

# Extract the zip file if it's not already extracted
if not os.path.exists(extraction_dir):
    with zipfile.ZipFile(test_data_dir, 'r') as zip_ref:
        zip_ref.extractall(extraction_dir)

# Now, you can list the contents of the extracted directory
filepaths = []
labels = []

# Assuming the structure is similar to folders for each class inside the zip
folds = os.listdir(extraction_dir)

for fold in folds:
    foldpath = os.path.join(extraction_dir, fold)

    # Check if the fold is indeed a directory (important for subfolders in zip)
    if os.path.isdir(foldpath):
        filelist = os.listdir(foldpath)

        for file in filelist:
            fpath = os.path.join(foldpath, file)

            # Append the file path and its label (the folder name)
            filepaths.append(fpath)
            labels.append(fold)

# Create a dataframe combining file paths and labels
Fseries = pd.Series(filepaths, name='filepaths')
Lseries = pd.Series(labels, name='labels')
test_df = pd.concat([Fseries, Lseries], axis=1)

# Show the first few rows of the dataframe
print(test_df.head())

test_df.head()

from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Import ImageDataGenerator

# Cropped image size
batch_size = 16
img_size = (224, 224)
channels = 3
img_shape = (img_size[0], img_size[1], channels)

# Initialize ImageDataGenerator for training and testing
tr_gen = ImageDataGenerator()
ts_gen = ImageDataGenerator()

# Create training data generator
train_gen = tr_gen.flow_from_dataframe(
    dataframe=train_df,
    x_col='filepaths',
    y_col='labels',
    target_size=img_size,
    class_mode='categorical',
    color_mode='rgb',
    shuffle=True,
    batch_size=batch_size
)

# Create testing data generator
test_gen = ts_gen.flow_from_dataframe(
    dataframe=test_df,
    x_col='filepaths',
    y_col='labels',
    target_size=img_size,
    class_mode='categorical',
    color_mode='rgb',
    shuffle=False,
    batch_size=batch_size
)

from tensorflow.keras.applications import MobileNetV2  # Import MobileNetV2
from tensorflow.keras.models import Sequential  # Import Sequential model
from tensorflow.keras.layers import BatchNormalization, Dense, Dropout, GlobalAveragePooling2D  # Import necessary layers
from tensorflow.keras import Input

# Image size and channels
img_size = (224, 224)
channels = 3
img_shape = (img_size[0], img_size[1], channels)
class_count = len(list(train_gen.class_indices.keys()))  # Get number of classes for the output layer

# Define the input layer explicitly
input_layer = Input(shape=img_shape)

# Load the MobileNetV2 model with pre-trained weights, excluding the top fully connected layers
base_model = MobileNetV2(include_top=False, weights="imagenet", input_tensor=input_layer)

# Freeze the base model layers to avoid retraining them
base_model.trainable = False

# Build the final model
model = Sequential([
    base_model,  # Add the base MobileNetV2 model
    GlobalAveragePooling2D(),  # Apply GlobalAveragePooling2D after MobileNetV2 base model
    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),  # Batch normalization layer
    Dense(512, activation='relu'),  # Dense layer with 512 units and ReLU activation
    Dropout(0.5),  # Dropout layer for regularization
    Dense(class_count, activation='softmax')  # Output layer with softmax for multi-class classification
])

# Summarize the model

# Define the correct image size for MobileNetV2
img_size = (224, 224)  # Set target size to (224, 224)

# Create the training data generator
train_gen = tr_gen.flow_from_dataframe(
    dataframe=train_df,
    x_col='filepaths',
    y_col='labels',
    target_size=img_size,  # Resize images to (224, 224)
    class_mode='categorical',
    color_mode='rgb',
    shuffle=True,
    batch_size=batch_size
)

# Create the testing data generator
test_gen = ts_gen.flow_from_dataframe(
    dataframe=test_df,
    x_col='filepaths',
    y_col='labels',
    target_size=img_size,  # Resize images to (224, 224)
    class_mode='categorical',
    color_mode='rgb',
    shuffle=False,
    batch_size=batch_size
)

# Assuming your data generators are defined elsewhere

def evaluate_model(model, data_generator, steps, verbose=1):
    """Evaluates a model using a data generator.

    Args:
        model: The Keras model to evaluate.
        data_generator: The data generator to provide data.
        steps: The number of steps (batches) to evaluate.
        verbose: Verbosity level (0 or 1).

    Returns:
        A list containing the loss and metrics values.
    """

    if len(data_generator) > 0:
        return model.evaluate(data_generator, steps=steps, verbose=verbose)
    else:
        print(f"{data_generator.__class__.__name__} is empty. Skipping evaluation.")
        return None

train_score = evaluate_model(model, train_gen, train_steps, verbose=1)
test_score = evaluate_model(model, test_gen, test_steps, verbose=1)

if train_score:
    print("Train Loss: ", train_score[0])
    print("Train Accuracy: ", train_score[1])

if test_score:
    print('-' * 20)
    print("Test Loss: ", test_score[0])
    print("Test Accuracy: ", test_score[1])